{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-27 14:46:18--  https://nlp100.github.io/data/ai.ja.zip\n",
      "nlp100.github.io (nlp100.github.io) をDNSに問いあわせています... 185.199.110.153, 185.199.111.153, 185.199.108.153, ...\n",
      "nlp100.github.io (nlp100.github.io)|185.199.110.153|:443 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 17516 (17K) [application/zip]\n",
      "`data/ai.ja.zip' に保存中\n",
      "\n",
      "ai.ja.zip           100%[===================>]  17.11K  --.-KB/s 時間 0.001s     \n",
      "\n",
      "2021-06-27 14:46:18 (14.2 MB/s) - `data/ai.ja.zip' へ保存完了 [17516/17516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc \"https://nlp100.github.io/data/ai.ja.zip\" -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/ai.ja.zip\n",
      "  inflating: ai.ja.txt               \n",
      "  inflating: readme.ai.ja.md         \n"
     ]
    }
   ],
   "source": [
    "!unzip data/ai.ja.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cabocha -f1 <data/ai.ja.txt >work/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 -1D 1/1 0.000000\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "EOS\n",
      "EOS\n",
      "* 0 17D 1/1 0.388993\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "* 1 17D 2/3 0.613549\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n"
     ]
    }
   ],
   "source": [
    "# 中身をみてみる\n",
    "!head work/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11744  32165 546121 work/ai.ja.txt.parsed\n"
     ]
    }
   ],
   "source": [
    "# 行数、単語数、バイト数の確認\n",
    "!wc work/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ai.ja.txt') as fi, open('work/ai.ja.txt.splited', 'w') as output_fi:\n",
    "    for line in fi:\n",
    "        output_fi.write(line.replace('。', '。\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cabocha -f1 <work/ai.ja.txt.splited >work/ai.ja.txt.splited.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from itertools import combinations\n",
    "import re\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[surface:人工 base:人工 pos:名詞 pos1:一般,\n",
      " surface:知能 base:知能 pos:名詞 pos1:一般,\n",
      " surface:（ base:（ pos:記号 pos1:括弧開,\n",
      " surface:じん base:じん pos:名詞 pos1:一般,\n",
      " surface:こうち base:こうち pos:名詞 pos1:一般,\n",
      " surface:のう base:のう pos:助詞 pos1:終助詞,\n",
      " surface:、 base:、 pos:記号 pos1:読点,\n",
      " surface:、 base:、 pos:記号 pos1:読点,\n",
      " surface:AI base:* pos:名詞 pos1:一般,\n",
      " surface:〈 base:〈 pos:記号 pos1:括弧開,\n",
      " surface:エーアイ base:* pos:名詞 pos1:固有名詞,\n",
      " surface:〉 base:〉 pos:記号 pos1:括弧閉,\n",
      " surface:） base:） pos:記号 pos1:括弧閉,\n",
      " surface:と base:と pos:助詞 pos1:格助詞,\n",
      " surface:は base:は pos:助詞 pos1:係助詞,\n",
      " surface:、 base:、 pos:記号 pos1:読点,\n",
      " surface:「 base:「 pos:記号 pos1:括弧開,\n",
      " surface:『 base:『 pos:記号 pos1:括弧開,\n",
      " surface:計算 base:計算 pos:名詞 pos1:サ変接続,\n",
      " surface:（ base:（ pos:記号 pos1:括弧開,\n",
      " surface:） base:） pos:記号 pos1:括弧閉,\n",
      " surface:』 base:』 pos:記号 pos1:括弧閉,\n",
      " surface:という base:という pos:助詞 pos1:格助詞,\n",
      " surface:概念 base:概念 pos:名詞 pos1:一般,\n",
      " surface:と base:と pos:助詞 pos1:並立助詞,\n",
      " surface:『 base:『 pos:記号 pos1:括弧開,\n",
      " surface:コンピュータ base:コンピュータ pos:名詞 pos1:一般,\n",
      " surface:（ base:（ pos:記号 pos1:括弧開,\n",
      " surface:） base:） pos:記号 pos1:括弧閉,\n",
      " surface:』 base:』 pos:記号 pos1:括弧閉,\n",
      " surface:という base:という pos:助詞 pos1:格助詞,\n",
      " surface:道具 base:道具 pos:名詞 pos1:一般,\n",
      " surface:を base:を pos:助詞 pos1:格助詞,\n",
      " surface:用い base:用いる pos:動詞 pos1:自立,\n",
      " surface:て base:て pos:助詞 pos1:接続助詞,\n",
      " surface:『 base:『 pos:記号 pos1:括弧開,\n",
      " surface:知能 base:知能 pos:名詞 pos1:一般,\n",
      " surface:』 base:』 pos:記号 pos1:括弧閉,\n",
      " surface:を base:を pos:助詞 pos1:格助詞,\n",
      " surface:研究 base:研究 pos:名詞 pos1:サ変接続,\n",
      " surface:する base:する pos:動詞 pos1:自立,\n",
      " surface:計算 base:計算 pos:名詞 pos1:サ変接続,\n",
      " surface:機 base:機 pos:名詞 pos1:接尾,\n",
      " surface:科学 base:科学 pos:名詞 pos1:一般,\n",
      " surface:（ base:（ pos:記号 pos1:括弧開,\n",
      " surface:） base:） pos:記号 pos1:括弧閉,\n",
      " surface:の base:の pos:助詞 pos1:連体化,\n",
      " surface:一 base:一 pos:名詞 pos1:数,\n",
      " surface:分野 base:分野 pos:名詞 pos1:一般,\n",
      " surface:」 base:」 pos:記号 pos1:括弧閉,\n",
      " surface:を base:を pos:助詞 pos1:格助詞,\n",
      " surface:指す base:指す pos:動詞 pos1:自立,\n",
      " surface:語 base:語 pos:名詞 pos1:一般,\n",
      " surface:。 base:。 pos:記号 pos1:句点]\n"
     ]
    }
   ],
   "source": [
    "class Morph:\n",
    "    def __init__(self, line):\n",
    "        self.surface,tmp = line.split('\\t')  # 表層系と形態素解析結果に分類\n",
    "        morph = tmp.split(',')\n",
    "        self.base = morph[6]  # 基本形\n",
    "        self.pos = morph[0]  # 品詞\n",
    "        self.pos1 = morph[1]  # 品詞細分類1\n",
    "        \n",
    "    def __repr__(self):  # リストの中身としてprintされる時も呼び出される\n",
    "        return 'surface:{} base:{} pos:{} pos1:{}'.format(self.surface,self.base,self.pos,self.pos1)\n",
    "        \n",
    "        \n",
    "# 解析結果を読み込む関数(一文のmorphオブジェクトのリストを返す)\n",
    "def cabocha_reader(file):\n",
    "    morphs_list = []  # 一文の解析結果を格納するリスト\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.rstrip('\\n')  # 改行を取り除く\n",
    "        if line.startswith('* '):  # 係り受け解析結果の行を飛ばす\n",
    "            continue\n",
    "        elif line == 'EOS':  # 文が終了した時点で解析結果のリストを返す\n",
    "            if morphs_list:  # 空のリスト以外をyieldで返す\n",
    "                yield morphs_list\n",
    "                morphs_list.clear()  # リストの初期化\n",
    "        else:  # 形態素解析結果について処理\n",
    "            morphs_list.append(Morph(line))\n",
    "\n",
    "            \n",
    "with open('work/ai.ja.txt.splited.parsed') as file:              \n",
    "    for morphs in islice(cabocha_reader(file),1,2):\n",
    "        pprint(morphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, morphs:「言語の dst:2 srcs:[]) (2, morphs:推論、 dst:3 srcs:[0, 1])\n",
      "(1, morphs:理解や dst:2 srcs:[]) (2, morphs:推論、 dst:3 srcs:[0, 1])\n",
      "(2, morphs:推論、 dst:3 srcs:[0, 1]) (3, morphs:問題解決などの dst:4 srcs:[2])\n",
      "(3, morphs:問題解決などの dst:4 srcs:[2]) (4, morphs:知的行動を dst:6 srcs:[3])\n",
      "(4, morphs:知的行動を dst:6 srcs:[3]) (6, morphs:代わって dst:8 srcs:[4, 5])\n",
      "(5, morphs:人間に dst:6 srcs:[]) (6, morphs:代わって dst:8 srcs:[4, 5])\n",
      "(6, morphs:代わって dst:8 srcs:[4, 5]) (8, morphs:行わせる dst:9 srcs:[6, 7])\n",
      "(7, morphs:コンピューターに dst:8 srcs:[]) (8, morphs:行わせる dst:9 srcs:[6, 7])\n",
      "(8, morphs:行わせる dst:9 srcs:[6, 7]) (9, morphs:技術」、または、 dst:16 srcs:[8])\n",
      "(9, morphs:技術」、または、 dst:16 srcs:[8]) (16, morphs:研究分野」とも dst:17 srcs:[9, 15])\n",
      "(10, morphs:「計算機 dst:11 srcs:[]) (11, morphs:（コンピュータ）による dst:13 srcs:[10])\n",
      "(11, morphs:（コンピュータ）による dst:13 srcs:[10]) (13, morphs:情報処理システムの dst:15 srcs:[11, 12])\n",
      "(12, morphs:知的な dst:13 srcs:[]) (13, morphs:情報処理システムの dst:15 srcs:[11, 12])\n",
      "(13, morphs:情報処理システムの dst:15 srcs:[11, 12]) (15, morphs:実現に関する dst:16 srcs:[13, 14])\n",
      "(14, morphs:設計や dst:15 srcs:[]) (15, morphs:実現に関する dst:16 srcs:[13, 14])\n",
      "(15, morphs:実現に関する dst:16 srcs:[13, 14]) (16, morphs:研究分野」とも dst:17 srcs:[9, 15])\n",
      "(16, morphs:研究分野」とも dst:17 srcs:[9, 15]) (17, morphs:される。 dst:-1 srcs:[16])\n",
      "(17, morphs:される。 dst:-1 srcs:[16]) 係り先無し\n"
     ]
    }
   ],
   "source": [
    "class Chunck(Morph):  # Morphクラスの継承\n",
    "    def __init__(self):\n",
    "        self.morph = []\n",
    "        self.dst = -1\n",
    "        self.srcs = []\n",
    "        \n",
    "    def __repr__(self):  # 文節ごとに単語を結合して出力するようにする\n",
    "        surface = ''.join(morph.surface for morph in self.morph)\n",
    "        return 'morphs:{} dst:{} srcs:{}'.format(surface,self.dst,self.srcs)\n",
    "        \n",
    "def parseCaboCha(file):\n",
    "    chunck_list = defaultdict(Chunck)  # Chunckオブジェクトで初期化する\n",
    "    for line in file:\n",
    "        line = line.rstrip('\\n')\n",
    "            \n",
    "        # 文末のとき\n",
    "        if line == 'EOS':\n",
    "            sorted_chunck_list = sorted(chunck_list.items())  # デフォルトはkeyによる昇順ソート\n",
    "            if sorted_chunck_list:\n",
    "                yield sorted_chunck_list\n",
    "                chunck_list.clear()\n",
    "                \n",
    "        # 係り受け解析情報の行\n",
    "        elif line.startswith('* '):\n",
    "            d = line.split(' ')  # スペースで区切る\n",
    "            idx = int(d[1])  # 係り先文節インデックス番号\n",
    "            dst = int(d[2].rstrip('D'))  # 係り元インデックス番号「\n",
    "            chunck_list[idx].dst = dst  # 係り先文節インデックス番号の代入\n",
    "            \n",
    "            # 係り元が存在する場合\n",
    "            if dst != -1:\n",
    "                chunck_list[dst].srcs.append(idx)  # 係り元文節インデックス番号の追加\n",
    "            \n",
    "        # 形態素解析情報の行        \n",
    "        else:\n",
    "            chunck_list[idx].morph.append(Morph(line))  # 解析結果をmorphオブジェクトにして追加\n",
    "\n",
    "# ８文目の文節の文字列と係り先を表示\n",
    "with open('work/ai.ja.txt.splited.parsed') as file:\n",
    "    for chuncks in islice(parseCaboCha(file),2,3):\n",
    "        for chunck in chuncks:\n",
    "            if chunck[1].dst != -1:\n",
    "                print(chunck,chuncks[chunck[1].dst])\n",
    "            else:\n",
    "                print(chunck,\"係り先無し\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能\t語\n",
      "じんこうちのう\t語\n",
      "AI\tエーアイとは\n",
      "エーアイとは\t語\n",
      "計算\tという\n",
      "という\t道具を\n",
      "概念と\t道具を\n",
      "コンピュータ\tという\n",
      "という\t道具を\n",
      "道具を\t用いて\n",
      "用いて\t研究する\n",
      "知能を\t研究する\n",
      "研究する\t計算機科学\n",
      "計算機科学\tの\n",
      "の\t一分野を\n",
      "一分野を\t指す\n",
      "指す\t語\n"
     ]
    }
   ],
   "source": [
    "class Chunck(Chunck):  # Chunckクラスの継承\n",
    "    def get_surface(self):  # 記号を取り除いて文節の表層形を抽出する関数\n",
    "        return ''.join(morph.surface for morph in self.morph if morph.pos != '記号')        \n",
    "\n",
    "with open('work/ai.ja.txt.splited.parsed') as file:\n",
    "    for chuncks in islice(parseCaboCha(file),0,2):  # Q41の関数を一文ずつ実行\n",
    "        for chunck in chuncks:\n",
    "            if chunck[1].dst != -1:  # 係り先がない文節をはじく\n",
    "                word1 = chunck[1].get_surface()\n",
    "                word2 = chuncks[chunck[1].dst][1].get_surface()\n",
    "                print(word1,word2,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道具を\t用いて\n",
      "知能を\t研究する\n",
      "一分野を\t指す\n",
      "知的行動を\t代わって\n",
      "人間に\t代わって\n",
      "コンピューターに\t行わせる\n",
      "研究分野とも\tされる\n"
     ]
    }
   ],
   "source": [
    "class Chunck(Chunck):  # Chunckクラスの継承\n",
    "    def is_pos(self,pos):  # ある品詞が文節に含まれているかどうかを判定する関数\n",
    "        is_pos = False\n",
    "        for morph in self.morph:\n",
    "            if morph.pos == pos:\n",
    "                is_pos = True\n",
    "        return is_pos\n",
    "    \n",
    "with open('work/ai.ja.txt.splited.parsed') as file:\n",
    "    for chuncks in islice(parseCaboCha(file),0,3): \n",
    "        for chunck in chuncks:\n",
    "            if chunck[1].dst != -1:  # 係り先がない文節をはじく\n",
    "                words1 = chunck[1].get_surface()  # 係り元文節\n",
    "                words2 = chuncks[chunck[1].dst][1].get_surface()  # 係り先文節\n",
    "                if chunck[1].is_pos('名詞') and chuncks[chunck[1].dst][1].is_pos('動詞'):\n",
    "                    print(words1,words2,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run, PIPE\n",
    "from graphviz import Digraph\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意のテキストをcabochaで解析する\n",
    "text = \"人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。\"\n",
    "\n",
    "command = f\"echo {text} | cabocha -f1\"  # textを係り受け解析\n",
    "process = run(command, shell=True, stdout=PIPE, stderr=PIPE)  # commandを実行\n",
    "lines = process.stdout.decode('UTF-8').splitlines()  # 標準出力を1行ごとのリストとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chuncks in parseCaboCha(lines):  # 引数の部分は標準出力をデコードし、改行で分割したリスト\n",
    "    edges = []\n",
    "    for i,chunck in enumerate(chuncks):\n",
    "        if chunck[1].dst != -1:  # 係り先がない文節をはじく\n",
    "            word1 = chunck[1].get_surface()  # 係り元文節\n",
    "            word2 = chuncks[chunck[1].dst][1].get_surface()  # 係り先文節\n",
    "            edges.append(((i,word1),(chunck[1].dst, word2)))\n",
    "\n",
    "# グラフの可視化\n",
    "g=pydot.graph_from_edges(edges, directed=True)\n",
    "g.write_png('work/q44.dot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (20200408.0750)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"62pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 62.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 58,-112 58,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">あ</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">か</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-71.7C27,-63.98 27,-54.71 27,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-46.1 27,-36.1 23.5,-46.1 30.5,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa5b54c35d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Digraph()\n",
    "G.node('1',label='あ')\n",
    "G.node('2',label='か')\n",
    "G.edge('1','2')\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (20200408.0750)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1173pt\" height=\"836pt\"\n",
       " viewBox=\"0.00 0.00 1172.69 836.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 832)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-832 1168.69,-832 1168.69,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"798.35\" cy=\"-234\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"798.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">人工知能</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"596.35\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.35\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">語</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;17 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M764.08,-221.13C726.53,-208.11 666.69,-187.38 629.56,-174.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"630.32,-171.07 619.73,-171.1 628.03,-177.68 630.32,-171.07\"/>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>34</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"596.35\" cy=\"-90\" rx=\"66.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.35\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">研究分野とも</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;34 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M596.35,-143.7C596.35,-135.98 596.35,-126.71 596.35,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"599.85,-118.1 596.35,-108.1 592.85,-118.1 599.85,-118.1\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"657.35\" cy=\"-234\" rx=\"74.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"657.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">じんこうちのう</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;17 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M642.58,-216.05C634.57,-206.86 624.56,-195.38 615.91,-185.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"618.53,-183.13 609.32,-177.89 613.25,-187.73 618.53,-183.13\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"422.35\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"422.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">AI</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"422.35\" cy=\"-234\" rx=\"65.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"422.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">エーアイとは</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422.35,-287.7C422.35,-279.98 422.35,-270.71 422.35,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.85,-262.1 422.35,-252.1 418.85,-262.1 425.85,-262.1\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;17 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.98,-218.67C489.15,-206.12 534.04,-188.07 564.15,-175.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"565.78,-179.07 573.75,-172.09 563.17,-172.57 565.78,-179.07\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"393.35\" cy=\"-810\" rx=\"29.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"393.35\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"393.35\" cy=\"-738\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"393.35\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">という</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M393.35,-791.7C393.35,-783.98 393.35,-774.71 393.35,-766.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"396.85,-766.1 393.35,-756.1 389.85,-766.1 396.85,-766.1\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"488.35\" cy=\"-666\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.35\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">道具を</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.03,-722.5C426.79,-712.36 445.35,-698.68 460.6,-687.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.71,-690.24 468.69,-681.49 458.56,-684.6 462.71,-690.24\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"488.35\" cy=\"-594\" rx=\"37.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.35\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">用いて</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M488.35,-647.7C488.35,-639.98 488.35,-630.71 488.35,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"491.85,-622.1 488.35,-612.1 484.85,-622.1 491.85,-622.1\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"488.35\" cy=\"-738\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.35\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">概念と</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;9 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M488.35,-719.7C488.35,-711.98 488.35,-702.71 488.35,-694.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"491.85,-694.1 488.35,-684.1 484.85,-694.1 491.85,-694.1\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"583.35\" cy=\"-810\" rx=\"66.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"583.35\" y=\"-806.3\" font-family=\"Times,serif\" font-size=\"14.00\">コンピュータ</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"583.35\" cy=\"-738\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"583.35\" y=\"-734.3\" font-family=\"Times,serif\" font-size=\"14.00\">という</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M583.35,-791.7C583.35,-783.98 583.35,-774.71 583.35,-766.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"586.85,-766.1 583.35,-756.1 579.85,-766.1 586.85,-766.1\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M563.66,-722.5C549.91,-712.36 531.34,-698.68 516.09,-687.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"518.13,-684.6 508.01,-681.49 513.98,-690.24 518.13,-684.6\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"535.35\" cy=\"-522\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.35\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">研究する</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M499.25,-576.76C504.98,-568.23 512.13,-557.58 518.55,-548.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"521.51,-549.89 524.18,-539.63 515.7,-545.98 521.51,-549.89\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"535.35\" cy=\"-450\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.35\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算機科学</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.35,-503.7C535.35,-495.98 535.35,-486.71 535.35,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.85,-478.1 535.35,-468.1 531.85,-478.1 538.85,-478.1\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"582.35\" cy=\"-594\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"582.35\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">知能を</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M571.21,-576.41C565.61,-568.08 558.71,-557.8 552.46,-548.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"555.21,-546.31 546.73,-539.96 549.4,-550.21 555.21,-546.31\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"535.35\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.35\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">の</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.35,-431.7C535.35,-423.98 535.35,-414.71 535.35,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.85,-406.1 535.35,-396.1 531.85,-406.1 538.85,-406.1\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"535.35\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">一分野を</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.35,-359.7C535.35,-351.98 535.35,-342.71 535.35,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.85,-334.1 535.35,-324.1 531.85,-334.1 538.85,-334.1\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"535.35\" cy=\"-234\" rx=\"29.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"535.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">指す</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M535.35,-287.7C535.35,-279.98 535.35,-270.71 535.35,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.85,-262.1 535.35,-252.1 531.85,-262.1 538.85,-262.1\"/>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M548.58,-217.81C556.74,-208.45 567.34,-196.28 576.49,-185.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"579.21,-188 583.14,-178.16 573.93,-183.4 579.21,-188\"/>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>35</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"596.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.35\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">される</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;35 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>34&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M596.35,-71.7C596.35,-63.98 596.35,-54.71 596.35,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"599.85,-46.1 596.35,-36.1 592.85,-46.1 599.85,-46.1\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-594\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">言語の</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"85.35\" cy=\"-522\" rx=\"29.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.35\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">推論</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.48,-576.41C55.3,-567.74 62.54,-556.97 68.98,-547.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.94,-549.24 74.61,-538.99 66.13,-545.34 71.94,-549.24\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"85.35\" cy=\"-450\" rx=\"74.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.35\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">問題解決などの</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.35,-503.7C85.35,-495.98 85.35,-486.71 85.35,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.85,-478.1 85.35,-468.1 81.85,-478.1 88.85,-478.1\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"133.35\" cy=\"-594\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.35\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">理解や</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>19&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.21,-576.76C116.28,-568.11 108.85,-557.27 102.22,-547.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.96,-545.42 96.42,-539.15 99.19,-549.37 104.96,-545.42\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>22</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"85.35\" cy=\"-378\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.35\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">知的行動を</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>21&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.35,-431.7C85.35,-423.98 85.35,-414.71 85.35,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.85,-406.1 85.35,-396.1 81.85,-406.1 88.85,-406.1\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"142.35\" cy=\"-306\" rx=\"46.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"142.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">代わって</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>22&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.85,-360.41C105.88,-351.78 114.61,-341.06 122.4,-331.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.34,-333.43 128.94,-323.47 119.91,-329.01 125.34,-333.43\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"292.35\" cy=\"-234\" rx=\"46.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">行わせる</text>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;26 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>24&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.91,-291.67C194.61,-280.61 228.5,-264.8 254.46,-252.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"256.05,-255.8 263.63,-248.4 253.09,-249.46 256.05,-255.8\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>23</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"199.35\" cy=\"-378\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"199.35\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">人間に</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;24 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>23&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.13,-360.76C179.04,-352.06 170.15,-341.15 162.24,-331.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164.92,-329.18 155.89,-323.63 159.49,-333.6 164.92,-329.18\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>27</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"424.35\" cy=\"-162\" rx=\"57.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.35\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">技術または</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>26&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.74,-219C338.36,-208.6 365.39,-194.27 387.19,-182.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"388.98,-185.72 396.17,-177.94 385.7,-179.53 388.98,-185.72\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>25</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"292.35\" cy=\"-306\" rx=\"85.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">コンピューターに</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>25&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M292.35,-287.7C292.35,-279.98 292.35,-270.71 292.35,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"295.85,-262.1 292.35,-252.1 288.85,-262.1 295.85,-262.1\"/>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;34 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>27&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.92,-147.34C484.62,-136.47 522.23,-121.17 551.5,-109.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"553.14,-112.36 561.09,-105.35 550.5,-105.88 553.14,-112.36\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>28</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"975.35\" cy=\"-378\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"975.35\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算機</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>29</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"975.35\" cy=\"-306\" rx=\"94.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"975.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">コンピュータによる</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>28&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M975.35,-359.7C975.35,-351.98 975.35,-342.71 975.35,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"978.85,-334.1 975.35,-324.1 971.85,-334.1 978.85,-334.1\"/>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>31</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1051.35\" cy=\"-234\" rx=\"92.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1051.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">情報処理システムの</text>\n",
       "</g>\n",
       "<!-- 29&#45;&gt;31 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>29&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M993.74,-288.05C1003.27,-279.28 1015.05,-268.43 1025.47,-258.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1028.13,-261.14 1033.12,-251.79 1023.39,-255.99 1028.13,-261.14\"/>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>33</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"902.35\" cy=\"-162\" rx=\"66.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.35\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">実現に関する</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;33 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>31&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1017.54,-217.12C995.5,-206.76 966.61,-193.19 943.28,-182.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"944.52,-178.95 933.99,-177.86 941.55,-185.28 944.52,-178.95\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>30</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1126.35\" cy=\"-306\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1126.35\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">知的な</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;31 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>30&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1109.7,-289.46C1100.05,-280.45 1087.69,-268.92 1076.83,-258.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1078.95,-255.98 1069.25,-251.71 1074.18,-261.1 1078.95,-255.98\"/>\n",
       "</g>\n",
       "<!-- 33&#45;&gt;34 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>33&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M853.18,-149.75C799.31,-137.43 712.93,-117.67 655.42,-104.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"655.92,-101.04 645.39,-102.22 654.36,-107.86 655.92,-101.04\"/>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>32</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"902.35\" cy=\"-234\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.35\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">設計や</text>\n",
       "</g>\n",
       "<!-- 32&#45;&gt;33 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>32&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M902.35,-215.7C902.35,-207.98 902.35,-198.71 902.35,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"905.85,-190.1 902.35,-180.1 898.85,-190.1 905.85,-190.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa5b54c3750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graphvizを使用\n",
    "G = Digraph()\n",
    "for src,dst in edges:\n",
    "    G.node(str(src[0]),label=src[1])\n",
    "    G.node(str(dst[0]),label=dst[1])\n",
    "    G.edge(str(src[0]),str(dst[0]))\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "- 述語に係る助詞を格とする\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "    作り出す\tで は を\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "- コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "- 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunck(Chunck):  # Chunckクラスの継承\n",
    "    def lfind(self,pos):  # posで指定された品詞の単語を返す関数(一番左のものを返す)\n",
    "        for morph in self.morph:\n",
    "            if morph.pos == pos:\n",
    "                return morph\n",
    "            \n",
    "    def rfind(self,pos):  # posで指定された品詞の単語を返す関数(一番右のものを返す)\n",
    "        flame = ''\n",
    "        for morph in self.morph:\n",
    "            if morph.pos == pos:\n",
    "                flame = morph.surface\n",
    "        return flame\n",
    "    \n",
    "# chunckオブジェクトのリストを受け取り、動詞を含む文節に対して述語と格を出力する\n",
    "with open('work/ai.ja.txt.splited.parsed') as read_file, open('work/case_flame.txt','w') as output_file:\n",
    "    for chuncks in parseCaboCha(read_file):\n",
    "        for chunck in chuncks:  # 各chunckに対して処理\n",
    "            if chunck[1].is_pos('動詞'):  # 動詞を含む文節のみ処理\n",
    "                verb = chunck[1].lfind('動詞')  # 最左の動詞を格納\n",
    "                \n",
    "                # 動詞にかかっている文節のなかで助詞が含まれている場合casesリストに追加\n",
    "                # 一つの文節に助詞が複数存在する場合は最右の助詞を取得\n",
    "                cases = (chuncks[src][1].rfind('助詞') for src in chunck[1].srcs)\n",
    "                # 空文字を除去\n",
    "                cases = filter(lambda x: x != '', cases)\n",
    "                # 格が存在していた時のみファイルに出力\n",
    "                if cases:\n",
    "                    print(verb.base,' '.join(sorted(cases)),sep='\\t',file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53 する\tを\n",
      "     19 する\tと\n",
      "     18 する\tが\n",
      "     16 する\tに\n",
      "     12 する\tは を\n",
      "     11 よる\tに\n",
      "     10 する\tに を\n",
      "      9 する\tで を\n",
      "      8 する\tと は\n",
      "      8 する\tが に\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "!sort -k 1 work/case_flame.txt | uniq -c | sort -nr | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 行う\tを\n",
      "      1 行う\tから\n",
      "      1 行う\tに により を\n",
      "      1 行う\tに まで を\n",
      "      1 行う\tは を をめぐって\n",
      "      1 行う\tで は まで を\n",
      "      1 行う\tが て に は\n",
      "      1 行う\tは は は\n",
      "      1 行う\tに を を\n",
      "      1 行う\tで に を\n"
     ]
    }
   ],
   "source": [
    "# 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）\n",
    "# awkコマンドで条件に文字列を使うときは\"\"で囲む\n",
    "!cat work/case_flame.txt | awk '$1 == \"行う\"' | uniq -c | sort -r | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 なる\tに は\n",
      "      1 なる\tから が て と は ば\n",
      "      1 なる\tから で と\n",
      "      1 なる\tが にとって は\n",
      "      1 なる\tて として に は\n",
      "      1 なる\tと など は\n",
      "      1 なる\tが で と に は は\n",
      "      1 なる\tで に は\n",
      "      1 なる\tが に は\n",
      "      1 なる\tが と に\n"
     ]
    }
   ],
   "source": [
    "!cat work/case_flame.txt | awk '$1 == \"なる\"' | uniq -c | sort -r | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 与える\tが に\n",
      "      1 与える\tに は を\n"
     ]
    }
   ],
   "source": [
    "!cat work/case_flame.txt | awk '$1 == \"与える\"' | uniq -c | sort -r | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "- 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである\n",
    "\n",
    "    作り出す\tで は を\t会議で ジョンマッカーシーは 用語を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunck(Chunck):  # Chunckクラスの継承\n",
    "    def rfind_and_getsurface(self,pos):  # posで指定された最右の品詞の単語とその文節の表層形を返す関数\n",
    "        flame,surface = '',''\n",
    "        for morph in self.morph:\n",
    "            if morph.pos != '記号':\n",
    "                surface += morph.surface\n",
    "            if morph.pos == pos:\n",
    "                flame = morph.surface\n",
    "        return flame,surface\n",
    "\n",
    "    \n",
    "# chunckオブジェクトのリストを受け取り、動詞を含む文節に対して述語と格を出力する\n",
    "with open('work/ai.ja.txt.splited.parsed') as read_file, open('work/case_flame_q46.txt','w') as output_file:\n",
    "    for chuncks in parseCaboCha(read_file):\n",
    "        for chunck in chuncks:  # 各chunckに対して処理\n",
    "            if chunck[1].is_pos('動詞'):  # 動詞を含む文節のみ処理\n",
    "                verb = chunck[1].lfind('動詞')  # 最左の動詞を格納\n",
    "                \n",
    "                # 動詞にかかっている文節のなかで助詞が含まれている場合casesリストにその助詞と文節を追加\n",
    "                # 一つの文節に助詞が複数存在する場合は最右の助詞を取得\n",
    "                cases = (chuncks[src][1].rfind_and_getsurface('助詞') for src in chunck[1].srcs)\n",
    "                # 空文字を除去\n",
    "                cases = filter(lambda x: x[0] != '', cases)\n",
    "                # 50音順にソート\n",
    "                cases = sorted(cases,key=lambda x:x[0])\n",
    "                # 格が存在していた時のみファイルに出力\n",
    "                if cases:\n",
    "                    cases,case_surface = zip(*cases)\n",
    "                    print(verb.base,' '.join(cases),' '.join(case_surface), sep='\\t',file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tを\t道具を\n",
      "する\tて を\t用いて 知能を\n",
      "指す\tを\t一分野を\n",
      "代わる\tに を\t人間に 知的行動を\n",
      "行う\tて に\t代わって コンピューターに\n",
      "する\tも\t研究分野とも\n",
      "述べる\tで に は\t解説で 次のように 佐藤理史は\n",
      "する\tで を\tコンピュータ上で 知的能力を\n",
      "する\tを\t推論判断を\n",
      "する\tを\t画像データを\n"
     ]
    }
   ],
   "source": [
    "!head work/case_flame_q46.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. 機能動詞構文のマイニング\n",
    "\n",
    "- コーパス中で頻出する述語（サ変接続名詞+を+動詞）\n",
    "- コーパス中で頻出する述語と助詞パターン\n",
    "\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "- 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "- 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "- 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "\n",
    "例えば「また、自らの経験を元に学習を行う強化学習という手法もある。」という文から，以下の出力が得られるはずである．\n",
    "\n",
    "    学習を行う\tに を\t元に 経験を"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  cabochaが改行でEOSを判定しているため、改行なしで複数文が続いている箇所に関しては非常に長い文と捉えられてしまう\n",
    "-  100本ノックの出力例をみる限り、「。」で１文とみなしてcabochaで解析しているようにみえるため、以下の処理を行って正確な１文区切りになおす\n",
    "    - ai.ja.txtの「。」を「。\\n」に置換する\n",
    "    - 置換したテキストファイルを用いてcabochaで解析をかける\n",
    "    - (これを行うともともと改行で終了していた箇所が「。\\n\\n」となり、解析をかけるとEOS\\nEOSのように空行がたくさん出てきてしまうが、これは自分のコードで空行を弾く処理を行っているため問題ない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunck(Chunck):\n",
    "    # 「品詞細分類がpos1の単語＋表層形がsurfaceである単語」で構成される文節の「〜」の部分を返す関数\n",
    "    def get_pos1_and_get_surface(self,pos1,surface):\n",
    "        ans = ''\n",
    "        for i in range(len(self.morph) - 1):\n",
    "            # 「品詞細分類がpos1の単語＋表層形がsurfaceである単語」となっている箇所があるか判定\n",
    "            if self.morph[i].pos1 == pos1 and self.morph[i+1].surface == surface:\n",
    "                ans = self.morph[i].surface + self.morph[i+1].surface\n",
    "        return ans\n",
    "\n",
    "    \n",
    "with open('work/ai.ja.txt.splited.parsed') as read_file, open('work/case_flame_q47.txt','w') as output_file:\n",
    "    for chuncks in parseCaboCha(read_file):\n",
    "        for chunck in chuncks:  # 各chunckに対して処理\n",
    "            # 動詞を含む文節について処理\n",
    "            if chunck[1].is_pos('動詞'):\n",
    "                verb = chunck[1].lfind('動詞')  # 最左の動詞を格納\n",
    "                cases = []\n",
    "                # 動詞にかかっている文節について処理\n",
    "                for src in chunck[1].srcs:\n",
    "                    sahen_wo = chuncks[src][1].get_pos1_and_get_surface('サ変接続','を')\n",
    "                    cases.append(chuncks[src][1].rfind_and_getsurface('助詞'))\n",
    "                # 「空文字」・「サ変接続＋を」を除去\n",
    "                cases = filter(lambda x: x[0] != '' and sahen_wo not in x[1], cases)\n",
    "                # 50音順にソート\n",
    "                cases = sorted(cases,key=lambda x:x[0])\n",
    "                # 格が存在していた時のみファイルに出力\n",
    "                if sahen_wo and cases:\n",
    "                    cases,case_surface = zip(*cases)\n",
    "                    print(sahen_wo + verb.base,' '.join(cases),' '.join(case_surface), sep='\\t',file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注目を集める\tが\tサポートベクターマシンが\n",
      "学習を行う\tに を\t元に 経験を\n",
      "進化を見せる\tて において は\t加えて 生成技術において 敵対的生成ネットワークは\n",
      "開発を行う\tは\tエイダ・ラブレスは\n",
      "処理を行う\tに により\tWebに ティム・バーナーズリーにより\n",
      "意味をする\tに\tデータに\n",
      "処理を行う\tて に\t付加して コンピュータに\n",
      "研究を進める\tて\t費やして\n",
      "運転をする\tに\t元に\n",
      "特許をする\tが に\t日本が 2018年までに\n"
     ]
    }
   ],
   "source": [
    "!head work/case_flame_q47.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. 名詞から根へのパスの抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 各文節は（表層形の）形態素列で表現する\n",
    "- パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "    ジョンマッカーシーは -> 作り出した\n",
    "    AIに関する -> 最初の -> 会議で -> 作り出した\n",
    "    最初の -> 会議で -> 作り出した\n",
    "    会議で -> 作り出した\n",
    "    人工知能という -> 用語を -> 作り出した\n",
    "    用語を -> 作り出した"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョンマッカーシーは -> 作り出した\n",
      "AIに関する -> 最初の -> 会議で -> 作り出した\n",
      "最初の -> 会議で -> 作り出した\n",
      "会議で -> 作り出した\n",
      "人工知能という -> 用語を -> 作り出した\n",
      "用語を -> 作り出した\n"
     ]
    }
   ],
   "source": [
    "with open('work/ai.ja.txt.splited.parsed') as read_file:\n",
    "    for chuncks in islice(parseCaboCha(read_file),33,34):\n",
    "        for chunck in chuncks:  # 各chunckに対して処理\n",
    "            path_list = []\n",
    "            if chunck[1].is_pos('名詞'):\n",
    "                next_word = chunck[1].dst  # 係り先の番号をnext_wordに\n",
    "                path_list.append(chunck[1].get_surface())  # パスに文節を追加\n",
    "                # 文末の文節にたどり着くまで係り先をたどっていく\n",
    "                while next_word != -1:\n",
    "                    path_list.append(chuncks[next_word][1].get_surface())  # 現在の位置の単語をパスに追加\n",
    "                    next_word = chuncks[next_word][1].dst  # 現在の位置を更新\n",
    "                print(' -> '.join(path_list))  # ' -> '区切りの文字列に直して出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. 名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n",
    "- 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n",
    "\n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "\n",
    "- 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "- 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "    Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
    "    Xは | Yの -> 会議で | 作り出した\n",
    "    Xは | Yで | 作り出した\n",
    "    Xは | Yという -> 用語を | 作り出した\n",
    "    Xは | Yを | 作り出した\n",
    "    Xに関する -> Yの\n",
    "    Xに関する -> 最初の -> Yで\n",
    "    Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
    "    Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
    "    Xの -> Yで\n",
    "    Xの -> 会議で | Yという -> 用語を | 作り出した\n",
    "    Xの -> 会議で | Yを | 作り出した\n",
    "    Xで | Yという -> 用語を | 作り出した\n",
    "    Xで | Yを | 作り出した\n",
    "    Xという -> Yを"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
      "Xは | Yの -> 会議で | 作り出した\n",
      "Xは | Yで | 作り出した\n",
      "Xは | Yという -> 用語を | 作り出した\n",
      "Xは | Yを | 作り出した\n",
      "Xに関する -> Yの\n",
      "Xに関する -> 最初の -> Yで\n",
      "Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
      "Xの -> Yで\n",
      "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xの -> 会議で | Yを | 作り出した\n",
      "Xで | Yという -> 用語を | 作り出した\n",
      "Xで | Yを | 作り出した\n",
      "Xという -> Yを\n"
     ]
    }
   ],
   "source": [
    "class Chunck(Chunck):\n",
    "    # 名詞をX,Yにマスクする関数\n",
    "    def mask_noun(self,mask):  # maskは\"X\"か\"Y\"が入る\n",
    "        ans = ''\n",
    "        for morph in self.morph:\n",
    "            if morph.pos == '名詞':\n",
    "                # 名詞が連続した時にXXやYYとならないように、直前にXやYを追加している場合は処理しない\n",
    "                if not ans or ans[-1] != mask:  \n",
    "                    ans += mask\n",
    "            elif morph.pos != '記号':\n",
    "                ans += morph.surface\n",
    "        return ans\n",
    "\n",
    "# n:文節番号　chuncks:文節情報 mask:XかY\n",
    "def change_xy(n,chuncks, mask):\n",
    "    x = ''\n",
    "    for word in chuncks[n][1].morph:\n",
    "        if word.pos == '名詞':x += mask\n",
    "        else:x += word.surface\n",
    "    return x\n",
    "    \n",
    "    \n",
    "with open('work/ai.ja.txt.splited.parsed') as read_file:\n",
    "    for chuncks in islice(parseCaboCha(read_file),33,34):\n",
    "        in_noun = {chunck[0] for chunck in chuncks if chunck[1].is_pos('名詞')}\n",
    "        \n",
    "    for a,b in combinations(in_noun,2):  # 文中で名詞が含まれる文節２つを選ぶ組み合わせごとに処理\n",
    "        butu = False  # aとbがぶつかるかどうか\n",
    "        b_index = -1  # 衝突先の文節番号を格納\n",
    "        x_move = set()  # 文節aの経路\n",
    "        \n",
    "        # aからbにぶつからないか\n",
    "        next_word = chuncks[a][1].dst\n",
    "        while next_word != -1:  # 文節aの経路を辿り文節bにぶつかるかどうかを探す\n",
    "            if next_word == b:\n",
    "                butu = True\n",
    "                break\n",
    "            x_move.add(next_word)  # 経路を格納\n",
    "            next_word = chuncks[next_word][1].dst\n",
    "        \n",
    "        # aとbが文末以外で共通の文節にぶつかっているか\n",
    "        if not butu:\n",
    "            next_word = chuncks[b][1].dst\n",
    "            while next_word != -1:  # 文節bの経路を辿り文節aの経路にぶつかるかどうかを探す\n",
    "                if next_word in x_move:\n",
    "                    b_index = chuncks[next_word][0]\n",
    "                    break\n",
    "                else:\n",
    "                    next_word = chuncks[next_word][1].dst\n",
    "    \n",
    "        # 出力\n",
    "        # 文節aが文節bにぶつかるパターン\n",
    "        if b_index == -1:\n",
    "            path_list,next_word = [chuncks[a][1].mask_noun('X')],chuncks[a][1].dst\n",
    "            while next_word != chuncks[b][1].dst:\n",
    "                path_list.append(chuncks[next_word][1].get_surface())\n",
    "                next_word = chuncks[next_word][1].dst\n",
    "            path_list[-1] = change_xy(b,chuncks,'Y')  # 文節bのマスク処理\n",
    "            print(' -> '.join(path_list))  # ' -> 'で連結して表示\n",
    "        \n",
    "    \n",
    "        # 共通の文節にぶつかるパターン\n",
    "        else:\n",
    "            x = ''\n",
    "            # 文節a,文節bそれぞについて処理\n",
    "            for i,j in zip((a,b),('X','Y')):\n",
    "                # 文節のマスク処理\n",
    "                path_list,next_word = [chuncks[i][1].mask_noun(j)],chuncks[i][1].dst\n",
    "                while next_word != b_index:\n",
    "                    path_list.append(chuncks[next_word][1].get_surface())\n",
    "                    next_word = chuncks[next_word][1].dst\n",
    "                x += ' -> '.join(path_list) + ' | '\n",
    "                \n",
    "            # 連結して出力\n",
    "            print(x + chuncks[b_index][1].get_surface())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
